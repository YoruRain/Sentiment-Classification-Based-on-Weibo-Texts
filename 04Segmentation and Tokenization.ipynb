{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a4fcf5",
   "metadata": {},
   "source": [
    "## 04 中文分词与词元化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05ded3",
   "metadata": {},
   "source": [
    "首先，我们读取从 `03 Data Augmentation.ipynb` 中保存的增强数据集，并将其拆分为训练集、验证集和测试集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9050d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据: 391818 行\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3d050763-7b6f-4d15-b0cf-b871966f471d",
       "rows": [
        [
         "0",
         "空心菜是世界上最好吃的青菜",
         "1"
        ],
        [
         "1",
         "下雪了？好美的雪啊",
         "1"
        ],
        [
         "2",
         "哈哈哈娱乐圈文必须有的环节之上综艺打电话环节，必给男主打电话",
         "1"
        ],
        [
         "3",
         "亚森发热 发热",
         "0"
        ],
        [
         "4",
         "人随春好，春与人宜。",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>空心菜是世界上最好吃的青菜</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>下雪了？好美的雪啊</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>哈哈哈娱乐圈文必须有的环节之上综艺打电话环节，必给男主打电话</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>亚森发热 发热</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>人随春好，春与人宜。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  sentiment_polarity\n",
       "0                   空心菜是世界上最好吃的青菜                   1\n",
       "1                       下雪了？好美的雪啊                   1\n",
       "2  哈哈哈娱乐圈文必须有的环节之上综艺打电话环节，必给男主打电话                   1\n",
       "3                         亚森发热 发热                   0\n",
       "4                      人随春好，春与人宜。                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('data/weibo_augmented.csv', encoding='utf-8-sig')\n",
    "\n",
    "df = df[[\"text\", \"sentiment_polarity\"]]\n",
    "print(f\"数据: {len(df)} 行\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d6c76",
   "metadata": {},
   "source": [
    "### 标签映射"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21b28e",
   "metadata": {},
   "source": [
    "可以看到，数据集使用 `[-1, 0, 1]` 表示情感极性。\n",
    "\n",
    "后续训练模型时会发现，反向传播时使用的损失函数（`NLLLoss` 或 `CrossEntropyLoss`）要求样本的标签为 `0 ~num_classes-1` 之间的整数，因此需要将情感标签从原始的 `[-1, 0, 1]` 映射到 `[0, 1, 2]`。\n",
    "\n",
    "这里使用函数 `remap_labels` 来实现标签的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e3b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "2    167778\n",
      "0    124334\n",
      "1     99706\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pandas import DataFrame\n",
    "\n",
    "def remap_labels(data: DataFrame, label_mapping={-1:0, 0:1, 1:2}):  #@save\n",
    "    if 2 in data[\"label\"].values:\n",
    "        return data\n",
    "    remapped_data = []\n",
    "    for tokens, old_label in data.values:\n",
    "        new_label = label_mapping.get(old_label, old_label)\n",
    "        remapped_data.append((tokens, new_label))\n",
    "    return DataFrame(remapped_data, columns=[\"text\", \"label\"])\n",
    "\n",
    "df = df.rename(columns={\"sentiment_polarity\": \"label\"})\n",
    "df = remap_labels(df)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f968908",
   "metadata": {},
   "source": [
    "### 划分数据集\n",
    "在机器学习任务中，通常需要将数据集划分为训练集、验证集和测试集，以便模型能够在不同的数据上进行训练和评估。\n",
    "\n",
    "训练集用于模型的训练，验证集用于调参和选择最佳模型，测试集用于最终评估模型的性能。\n",
    "\n",
    "`sklearn.model_selection` 模块提供了方便的函数 `train_test_split`，可以轻松地将数据集划分为不同的子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb446988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274272, 58773, 58773)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f1e4f",
   "metadata": {},
   "source": [
    "划分数据集结束后，先将每一类的数据集合并为一个 DataFrame，然后保存到本地，方便后续的模型读取处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b5914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_raw.txt 已存在，跳过保存。\n",
      "data/val_raw.txt 已存在，跳过保存。\n",
      "data/test_raw.txt 已存在，跳过保存。\n"
     ]
    }
   ],
   "source": [
    "train_raw = DataFrame({\"text\": X_train, \"label\": y_train})\n",
    "val_raw = DataFrame({\"text\": X_val, \"label\": y_val})\n",
    "test_raw = DataFrame({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "def save_data(data: DataFrame, file_path: str, sep: str = ''):  #@save\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"{file_path} 已存在，跳过保存。\")\n",
    "        return\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for X, y in data.values:\n",
    "            if not sep:\n",
    "                f.write(f\"{X}:{y}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{sep.join(map(str, X))}:{y}\\n\")\n",
    "    print(f\"已保存到 {file_path}。\")\n",
    "\n",
    "save_data(train_raw, 'data/train_raw.txt')\n",
    "save_data(val_raw, 'data/val_raw.txt')\n",
    "save_data(test_raw, 'data/test_raw.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa3f11",
   "metadata": {},
   "source": [
    "接下来，我们要考虑文本数据的分词与词元化处理。\n",
    "\n",
    "\n",
    "分词（Word Segmentation）是中文自然语言处理中的基础任务，旨在将连续的汉字序列切分成有意义的词语单元。与英文等语言不同，中文文本中词语之间没有明确的空格分隔符，这使得分词成为中文 NLP 任务中的一个关键步骤。\n",
    "\n",
    "词元化（Tokenization）是将文本转换为模型可处理的数值形式的过程。对于基于词袋模型（Bag-of-Words）或词嵌入（Word Embeddings）的模型，词元化通常涉及将分词后的词语映射到唯一的整数索引，形成词汇表（Vocabulary）。\n",
    "\n",
    "下面我们将逐步完成分词、构建词汇表以及词元化的过程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0479a8",
   "metadata": {},
   "source": [
    "### 分词（Word Segmentation）\n",
    "\n",
    "我们使用 LTP 作为分词工具。LTP（Language Technology Platform，语言技术平台）是哈尔滨工业大学社会计算与信息检索研究中心（HIT-SCIR）历时多年研发的一整套高效、高精度的中文自然语言处理开源基础技术平台。相较于常用的分词工具如 Jieba，LTP 在分词方面各方面的表现均较为优秀，适合用于对文本进行高质量的分词处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a9501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理训练集...\n",
      "文件 data/train_segmented.txt 已存在，直接读取。\n",
      "\n",
      "开始处理验证集...\n",
      "文件 data/val_segmented.txt 已存在，直接读取。\n",
      "\n",
      "开始处理测试集...\n",
      "文件 data/test_segmented.txt 已存在，直接读取。\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def segment_data(X, y, file_path='', batch_size=500):  #@save\n",
    "    \"\"\"\n",
    "    分批处理数据以避免内存不足问题\n",
    "    batch_size: 每批处理的数据量，默认1000条\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"文件 {file_path} 已存在，直接读取。\")\n",
    "        return load_data(file_path, sep='<sp>', is_segmented=True)\n",
    "    if not isinstance(X, list):\n",
    "        X = X.tolist()\n",
    "    if not isinstance(y, list):\n",
    "        y = y.tolist()\n",
    "    \n",
    "    from ltp import LTP\n",
    "    ltp = LTP()\n",
    "\n",
    "    segmented_data = []\n",
    "    \n",
    "    print(f\"开始处理 {len(X)} 条数据，批大小: {batch_size}\")\n",
    "    \n",
    "    if len(file_path) > 0:\n",
    "        # 打开文件准备写入\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            # 分批处理\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                batch_end = min(i + batch_size, len(X))\n",
    "                batch_X = X[i:batch_end]\n",
    "                batch_y = y[i:batch_end]\n",
    "                \n",
    "                print(f\"正在处理第 {i//batch_size + 1} 批，数据范围: {i}-{batch_end-1}\")\n",
    "                \n",
    "                # 对当前批次进行分词\n",
    "                segment = ltp.pipeline(batch_X, tasks=['cws'], return_dict=False)[0]\n",
    "                \n",
    "                # 写入文件\n",
    "                for sublist, label in zip(segment, batch_y):\n",
    "                    segmented_data.append((sublist, label))\n",
    "                    f.write('<sp>'.join(sublist) + ':' + str(label) + '\\n')\n",
    "                \n",
    "                print(f\"第 {i//batch_size + 1} 批处理完成\")\n",
    "    \n",
    "    print(\"所有数据处理完成！\")\n",
    "    return DataFrame(segmented_data, columns=[\"text\", \"label\"])\n",
    "\n",
    "def load_data(  #@save\n",
    "        file_path: str, \n",
    "        sep='', \n",
    "        is_segmented=False, \n",
    "        is_indexed=False) -> DataFrame:\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        for line in f:\n",
    "            X, y = line.rsplit(':', 1)\n",
    "            if is_segmented:\n",
    "                X = [token.strip() for token in X.split(sep) if token.strip() != '']\n",
    "            elif is_indexed:\n",
    "                X = list(map(int, X.split(sep)))\n",
    "            y = int(float(y))\n",
    "            data.append((X, y))\n",
    "    return DataFrame(data, columns=[\"text\", \"label\"])\n",
    "\n",
    "\n",
    "# 分批处理数据，使用较小的批大小以避免内存问题\n",
    "print(\"开始处理训练集...\")\n",
    "train_seg = segment_data(X_train, y_train, 'data/train_segmented.txt', batch_size=500)\n",
    "\n",
    "print(\"\\n开始处理验证集...\")\n",
    "val_seg = segment_data(X_val, y_val, 'data/val_segmented.txt', batch_size=500)\n",
    "\n",
    "print(\"\\n开始处理测试集...\")\n",
    "test_seg = segment_data(X_test, y_test, 'data/test_segmented.txt', batch_size=500);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd457c",
   "metadata": {},
   "source": [
    "### 构建词汇表（Vocabulary）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462c532",
   "metadata": {},
   "source": [
    "仅使用训练集的数据构建词表 `vocab`："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cbf5cc",
   "metadata": {},
   "source": [
    "事先统计训练集中所有词元的词频，用于确认构建词表 `vocab` 的最小词频 `min_freq` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3d82aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "token_counts = Counter(token for text in train_seg[\"text\"] for token in text)\n",
    "freqs = list(token_counts.values())\n",
    "plt.hist(freqs, bins=100, range=(0,50))\n",
    "plt.xlabel('词元数量')\n",
    "plt.ylabel('词频')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b64a6",
   "metadata": {},
   "source": [
    "查看频率最高的前50个词元："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8cefd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 144710),\n",
       " ('了', 106081),\n",
       " ('，', 94593),\n",
       " ('我', 91165),\n",
       " ('是', 47330),\n",
       " ('不', 44745),\n",
       " ('。', 44400),\n",
       " ('！', 40256),\n",
       " ('一', 36995),\n",
       " ('好', 32474),\n",
       " ('啊', 31787),\n",
       " ('就', 23180),\n",
       " ('在', 23117),\n",
       " ('都', 22244),\n",
       " ('想', 19552),\n",
       " ('你', 19024),\n",
       " ('有', 17667),\n",
       " ('要', 16711),\n",
       " ('人', 16406),\n",
       " ('吃', 16365),\n",
       " ('天', 15714),\n",
       " ('到', 15601),\n",
       " ('这', 14765),\n",
       " ('个', 14703),\n",
       " ('也', 14267),\n",
       " ('看', 13837),\n",
       " ('又', 13481),\n",
       " ('能', 13446),\n",
       " ('很', 13358),\n",
       " ('和', 12564),\n",
       " ('没', 12309),\n",
       " ('会', 11981),\n",
       " ('今天', 11959),\n",
       " ('一个', 11397),\n",
       " ('真', 11079),\n",
       " ('去', 11045),\n",
       " ('小', 11015),\n",
       " ('上', 10775),\n",
       " (',', 10744),\n",
       " ('还', 10578),\n",
       " ('太', 10577),\n",
       " ('自己', 10500),\n",
       " ('来', 10051),\n",
       " ('着', 8776),\n",
       " ('给', 8144),\n",
       " ('多', 7966),\n",
       " ('得', 7604),\n",
       " ('说', 7598),\n",
       " ('这个', 7540),\n",
       " ('吧', 7375)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321b2b9",
   "metadata": {},
   "source": [
    "分析：\n",
    "- 出现标点符号：如 `，`、`。`、`！` 等\n",
    "    - 对于分句作用的符号，如 `，`、`。`、`、` 等，对于情感表达的作用不大，可以考虑去除。\n",
    "    - 对于表示情感的符号，如 `！`、`？` 等，可以考虑保留。\n",
    "- 出现虚词，如 `的`、`了`、`在`\n",
    "    - 尽管此类词语在语义上作用不大，但：\n",
    "        - 对传统机器学习来说，可通过权重自动弱化\n",
    "        - 对深度模型来说，它们的词嵌入会自动学到较弱权重\n",
    "    - 因此考虑保留此类词语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66a7db",
   "metadata": {},
   "source": [
    "查看词元计数器中出现的所有标点符号："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269e4c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('！', 40256),\n",
       " ('，', 94593),\n",
       " (',', 10744),\n",
       " ('?', 2072),\n",
       " ('。', 44400),\n",
       " ('？', 7318),\n",
       " ('（', 4378),\n",
       " ('）', 3270),\n",
       " ('：', 5382),\n",
       " ('_', 310),\n",
       " ('!', 401),\n",
       " ('(', 3017),\n",
       " (')', 2995),\n",
       " ('《', 43),\n",
       " ('》', 43),\n",
       " (':', 527),\n",
       " ('\"', 390),\n",
       " ('【', 478),\n",
       " ('】', 460),\n",
       " ('；', 184),\n",
       " ('、', 468),\n",
       " (';', 20),\n",
       " ('%', 5),\n",
       " ('...', 47),\n",
       " ('..', 2),\n",
       " ('.', 61),\n",
       " ('-', 42),\n",
       " ('“', 39),\n",
       " ('”', 30),\n",
       " ('____________', 1),\n",
       " ('#', 81),\n",
       " ('[', 6),\n",
       " (']', 6),\n",
       " ('__________', 1),\n",
       " ('___', 6),\n",
       " ('*', 3),\n",
       " ('_____', 2),\n",
       " ('____', 4),\n",
       " ('###', 3),\n",
       " ('@', 1),\n",
       " ('##', 3),\n",
       " ('¶', 4),\n",
       " ('（）', 1),\n",
       " ('」', 1),\n",
       " ('__', 5),\n",
       " ('______', 1),\n",
       " ('}', 1),\n",
       " ('_______', 1),\n",
       " ('________', 1),\n",
       " ('\\\\', 1),\n",
       " (\"'\", 1),\n",
       " ('§', 2)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "punct_tokens = [\n",
    "    (t, freq) for t, freq in token_counts.items() \n",
    "    if all(unicodedata.category(ch).startswith('P') \n",
    "           for ch in t)]\n",
    "\n",
    "punct_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71dcf1",
   "metadata": {},
   "source": [
    "对标点符号的进一步分类与分析：\n",
    "- 表示情感的符号：如 `！`、`？` 等，保留\n",
    "\n",
    "- 分句符号：如 `，`、`。`、`；` 等，去除\n",
    "\n",
    "- 结构性符号：如 `（`、`）`、`【`、`】` 等，去除\n",
    "\n",
    "- 异常符号（人工添加线）：如 `_`、`__` 等，去除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e3f3fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273045, 58466, 58491)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_punct(data: DataFrame):\n",
    "    \"\"\"\n",
    "    清理数据集中所有句子中的标点符号\n",
    "    保留表示情感的符号，去除其他标点符号\n",
    "    \"\"\"\n",
    "    remove_punct = {'，', ',', '。', '；', ';',  '：', ';',\n",
    "                     '\"', '“', '”', '（', '）', '(', ')',  '【', '】', '[', ']',  '《', '》', \n",
    "                     '#', '_'}\n",
    "    cleaned_data = []\n",
    "    \n",
    "    removed_index = []\n",
    "    # 直接操作数据，避免重复创建DataFrame\n",
    "    for index, tokens, label in data.itertuples():\n",
    "        cleaned_sentence = [token for token in tokens if token not in remove_punct]\n",
    "        if len(''.join(cleaned_sentence)) <= 3:\n",
    "            removed_index.append(index)\n",
    "        else:\n",
    "            cleaned_data.append([cleaned_sentence, label])\n",
    "    \n",
    "    # 一次性创建DataFrame\n",
    "    return pd.DataFrame(cleaned_data, columns=[\"text\", \"label\"]), removed_index\n",
    "\n",
    "\n",
    "train_seg, train_removed = clean_punct(train_seg)\n",
    "val_seg, val_removed = clean_punct(val_seg)\n",
    "test_seg, test_removed = clean_punct(test_seg)\n",
    "\n",
    "len(train_seg), len(val_seg), len(test_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76754fa",
   "metadata": {},
   "source": [
    "上面的函数记录并返回了被删除的样本的索引，根据索引便可以删除原始数据集中对应的样本，保持了后续所有模型的输入样本的一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e98a7c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274272 58773 58773\n",
      "273045 58466 58491\n"
     ]
    }
   ],
   "source": [
    "def remove_data_by_index(data: DataFrame, indices: list):\n",
    "    \"\"\"根据索引列表删除DataFrame中的对应行\"\"\"\n",
    "    return data.drop(index=indices).reset_index(drop=True)\n",
    "\n",
    "train_raw = remove_data_by_index(train_raw, train_removed)\n",
    "val_raw = remove_data_by_index(val_raw, val_removed)\n",
    "test_raw = remove_data_by_index(test_raw, test_removed)\n",
    "\n",
    "print(len(train_raw), len(val_raw), len(test_raw))\n",
    "print(len(train_seg), len(val_seg), len(test_seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc667e54",
   "metadata": {},
   "source": [
    "构建词表参数 `min_freq` 的设置分析：统计覆盖率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "530059c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_freq: 1\tcoverage: 1.0\n",
      "min_freq: 2\tcoverage: 0.975907699306043\n",
      "min_freq: 3\tcoverage: 0.966176266050107\n",
      "min_freq: 5\tcoverage: 0.9534520308999841\n",
      "min_freq: 10\tcoverage: 0.9332263189845745\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token_counts = Counter(token for sentence in train_seg[\"text\"] for token in sentence)\n",
    "total_tokens = sum(token_counts.values())\n",
    "\n",
    "for mf in [1, 2, 3, 5, 10]:\n",
    "    kept_tokens = sum(count for count in token_counts.values() if count >= mf)\n",
    "    print(f\"min_freq: {mf}\\tcoverage: {kept_tokens / total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ad6a6",
   "metadata": {},
   "source": [
    "一般来说，当覆盖率 `coverage` 不小于 95% 时，过滤效果比较合理。\n",
    "\n",
    "因此，构建词汇表时，我们设置最小词频 `min_freq=3`，即词频小于3的词元将被视为 `<UNK>` 词元，最终可达到约96.6%的覆盖率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43d6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None) -> None:\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx[\"<unk>\"]\n",
    "\n",
    "    @classmethod\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        \n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() \n",
    "                        if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self, token):\n",
    "        \"\"\"查找输入词元对应的索引值，若不存在，则返回<unk>的索引值（0）\"\"\"\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        \"\"\"查找一系列输入词元的索引值\"\"\"\n",
    "        return [self[token] for token in tokens]\n",
    "    \n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        \"\"\"查找一系列输入索引值对应的词元\"\"\"\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "def save_vocab(vocab: Vocab, file_path: str):\n",
    "    with open(file_path, 'w', encoding='utf-8-sig') as f:\n",
    "        f.write('\\n'.join(vocab.idx_to_token))\n",
    "\n",
    "def read_vocab(file_path: str) -> Vocab:\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        tokens = f.read().split('\\n')\n",
    "    return Vocab(tokens)\n",
    "\n",
    "vocab = Vocab.build(train_seg[\"text\"], min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7adf0484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35366"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933bdb3",
   "metadata": {},
   "source": [
    "### 词元化（Tokenization）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dafae0",
   "metadata": {},
   "source": [
    "构建好词汇表后，就可以进行词元化处理。具体来说，对数据集中每个句子使用 `vocab.convert_tokens_to_ids` 方法，将句子中的每个词元转换为词元在词汇表中的索引序列，供后续模型训练使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4df8da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = DataFrame([\n",
    "    [vocab.convert_tokens_to_ids(text), label]\n",
    "    for text, label in train_seg.values\n",
    "], columns=[\"text\", \"label\"])\n",
    "val_tok = DataFrame([\n",
    "    [vocab.convert_tokens_to_ids(text), label]\n",
    "    for text, label in val_seg.values\n",
    "], columns=[\"text\", \"label\"])\n",
    "test_tok = DataFrame([\n",
    "    [vocab.convert_tokens_to_ids(text), label]\n",
    "    for text, label in test_seg.values\n",
    "], columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4251d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 1：\n",
      "原始句子： ['过年', '进度', '条']\n",
      "词元索引： [1, 2, 3]\n",
      "\n",
      "样本 2：\n",
      "原始句子： ['运动', '使', '我', '快乐']\n",
      "词元索引： [4, 5, 6, 7]\n",
      "\n",
      "样本 3：\n",
      "原始句子： ['哈哈哈', '霸道', '总裁', '爱上', '我']\n",
      "词元索引： [8, 9, 10, 11, 6]\n",
      "\n",
      "样本 4：\n",
      "原始句子： ['私人号', '变成', '工作号', '之后', '每天', '刷', '不', '到', '活人', '朋友圈', '！', '！']\n",
      "词元索引： [0, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21]\n",
      "\n",
      "样本 5：\n",
      "原始句子： ['失败', '的', '贝果']\n",
      "词元索引： [22, 23, 24]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"样本 {i+1}：\")\n",
    "    print(\"原始句子：\", train_seg['text'].iloc[i])\n",
    "    print(\"词元索引：\", train_tok['text'].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d68eb4",
   "metadata": {},
   "source": [
    "将数据集与词汇表保存至本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93be4b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_tokenized.txt 已存在，跳过保存。\n",
      "data/val_tokenized.txt 已存在，跳过保存。\n",
      "data/test_tokenized.txt 已存在，跳过保存。\n"
     ]
    }
   ],
   "source": [
    "save_data(train_tok, 'data/train_tokenized.txt', sep=',')\n",
    "save_data(val_tok, 'data/val_tokenized.txt', sep=',')\n",
    "save_data(test_tok, 'data/test_tokenized.txt', sep=',')\n",
    "\n",
    "save_vocab(vocab, 'data/vocab.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpllma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
